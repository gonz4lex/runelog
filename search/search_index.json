{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RuneLog","text":"<p>RuneLog is a lightweight, file-based Python library for tracking machine learning experiments.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Track runs, metrics, and artifacts with zero-overhead setup</li> <li>Compare runs visually via a Streamlit UI</li> <li>Easy Python API + CLI</li> <li>Local-first, transparent storage</li> <li>Experiment and run management</li> <li>Parameter, metric, and artifact logging</li> <li>Model registry for saved models and versioning</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install runelog\n</code></pre>"},{"location":"#get-started","title":"Get Started","text":"<p>See Quickstart for a simple example.</p> <p>For more details, check out the API Reference and UI Guide.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to RuneLog will be documented in this file.</p>"},{"location":"CHANGELOG/#unreleased","title":"[Unreleased]","text":""},{"location":"CHANGELOG/#planned","title":"Planned","text":"<ul> <li><code>runelog serve</code> command to deploy modfels as a local API</li> <li>Lightweight feature store implementation</li> <li>More visualizations options, i.e. ROC curves, feature importances, confusion matrices</li> <li>Extensible plugin architecture for custom trackers or visualizations</li> </ul>"},{"location":"CHANGELOG/#020-2025-08-13","title":"[0.2.0] - 2025-08-13","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Git Integration: Automatically logs the Git commit hash, branch name, and repository \"dirty\" status for every run to a <code>source_control.json</code> file.</li> <li>Environment Snapshot: Automatically logs the Python version, platform information, and a full list of installed packages to an <code>environment.json</code> file. It also creates a pip-installable <code>requirements.txt</code> as a run artifact.</li> <li>Automatic Code Logging: Now includes an opt-in feature in <code>start_run</code> to automatically save a copy of the executing script as an artifact.</li> <li>Data Versioning:<ul> <li>Data Hashing: Added <code>tracker.log_dataset()</code>, a new method that calculates a SHA256 hash of a data file and saves it to a <code>data_meta.json</code> file for verifiable data lineage.</li> <li>DVC Integration: Added <code>tracker.log_dvc_input()</code>, a helper that reads the hash from a <code>.dvc</code> file to link runs with DVC-managed data.</li> </ul> </li> <li>Run Lineage: Added <code>tracker.log_input_run()</code>, which creates a <code>lineage.json</code> file to explicitly link a run to its upstream dependencies, such as a feature generation run.</li> <li>Documentation: Added a new guide explaining the \"Lightweight Feature Store\" pattern and a guide for the new DVC integration.</li> </ul>"},{"location":"CHANGELOG/#011-2025-08-04","title":"[0.1.1] - 2025-08-04","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>The <code>start_run</code> method now accepts an <code>experiment_name</code> directly, simplifying the most common user workflow.</li> <li>Added <code>delete_run</code> method to the core library for better cleanup and management.</li> <li>Added <code>runs delete</code> command with interactive confirmation prompts for safety.</li> <li>Improved empty state of the Streamlit UI for fresh runs, showing a brief quickstart when no experiments exist yet.</li> </ul>"},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>Corrected the development installation instructions in the <code>README.md</code> and contribution guides.</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Refactored <code>pyproject.toml</code> to use a pure <code>hatchling</code> build backend and a new <code>Hatch</code> environments for <code>docs</code>.</li> <li>Changed usage examples in <code>examples/</code> to reflect API changes.</li> </ul>"},{"location":"CHANGELOG/#010-2025-07-30","title":"[0.1.0] \u2013 2025-07-30","text":""},{"location":"CHANGELOG/#initial-release","title":"\ud83c\udf89 Initial Release","text":""},{"location":"CHANGELOG/#core-library","title":"Core Library","text":"<ul> <li>Experiment Tracking: <code>RuneLog</code> class for managing experiments and runs. Supports logging parameters, metrics, artifacts, and models.</li> <li>Model Registry: Full-featured model registry with versioning and tagging.</li> <li>Sweep Runner: <code>run_sweep</code> function for automated experiments from a flexible YAML configuration file.</li> <li>Custom Exceptions: A full suite of specific exceptions for robust error handling.</li> </ul>"},{"location":"CHANGELOG/#command-line-interface-cli","title":"Command-Line Interface (CLI)","text":"<ul> <li>A full-featured CLI powered by <code>Typer</code> and <code>rich</code>.</li> <li><code>runelog experiments</code>: <code>list</code>, <code>get</code>, <code>delete</code> or <code>export</code> experiments to CSV.</li> <li><code>runelog runs</code>: <code>list</code>, <code>get</code>, <code>compare</code> runs side-by-side, and <code>download-artifact</code>.</li> <li><code>runelog registry</code>: <code>list</code> models, <code>get-versions</code>, <code>register</code> a model, and <code>tag</code> versions.</li> <li><code>runelog sweep</code>: Execute a sweep from a config file.</li> <li><code>runelog ui</code>: Launch the web UI.</li> <li><code>runelog examples</code>: Commands to run example scripts.</li> </ul>"},{"location":"CHANGELOG/#web-ui-streamlit","title":"Web UI (Streamlit)","text":"<ul> <li>Experiment Explorer: View experiments and runs with a detailed drill-down view.</li> <li>Visual Run Comparison: Select multiple runs to see an interactive bar chart comparing their performance.</li> <li>Artifact Previewer: Render common artifact types like images and text files directly in the UI.</li> <li>Model Registry Viewer: Browse registered models and their versions.</li> <li>Register from UI: A button in the run detail view to register a model directly.</li> </ul>"},{"location":"CHANGELOG/#project-development","title":"Project &amp; Development","text":"<ul> <li>Professional Project Structure: Uses a <code>src</code>-layout managed by <code>Hatch</code>.</li> <li>Testing: Comprehensive test suite using <code>pytest</code>, including unit and integration tests.</li> <li>Docker Support: <code>Dockerfile</code> and <code>docker-compose.yml</code> to easily build and share the UI.</li> <li>Documentation: A full documentation site built with <code>mkdocs</code>.</li> <li>Community Files: <code>LICENSE</code>, <code>CONTRIBUTING.md</code>, and <code>CODE_OF_CONDUCT.md</code>.</li> </ul>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at hello@alexgonzalezc.dev. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"CONTRIBUTING/","title":"How to Contribute to RuneLog","text":"<p>Thank you for your interest in contributing to Runelog! We welcome all contributions, from bug reports to new features. This guide will help you get started.</p>"},{"location":"CONTRIBUTING/#how-can-i-contribute","title":"How Can I Contribute?","text":"<ul> <li>Reporting bugs: If you find a bug, please open an issue and provide a clear title, a description of the bug, steps to reproduce it, and what you expected to happen.</li> <li>Suggesting enhancements: If you have an idea for a new feature or an improvement, open an issue to start a discussion. This is the best way to ensure your idea aligns with the project's goals before you start working on it.</li> <li>Pull requests: We welcome pull requests for bug fixes, new features, and documentation improvements.</li> </ul>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting Up Your Development Environment","text":"<p>To get started with the code, follow these steps:</p> <ol> <li> <p>Fork the Repository: Click the \"Fork\" button on the top right of the GitHub repository page.</p> </li> <li> <p>Clone Your Fork: Clone your forked repository to your local machine.</p> </li> </ol> <pre><code>git clone https://github.com/gonz4lex/runelog.git\ncd runelog\n</code></pre> <ol> <li>Create a Virtual Environment: We recommend using a Python virtual environment.</li> </ol> <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows, use `.venv\\Scripts\\activate`\n</code></pre> <ol> <li>Install in Editable Mode: Install the project and its dependencies in \"editable\" mode. This allows you to import your local runelog package and have any changes you make to the source code be immediately available.</li> </ol> <pre><code>pip install -e .\n</code></pre> <p>You may also need to install development dependencies like pytest if you plan to run tests.</p> <pre><code>pip install pytest\n</code></pre>"},{"location":"CONTRIBUTING/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create new branch: All contributions should be made from a feature branch. Make sure your develop branch is up-to-date, then create a new branch for your feature.</li> </ol> <pre><code>git checkout develop\ngit pull origin develop\ngit checkout -b feat/my-new-feature\n</code></pre> <ol> <li> <p>Make your changes: Write your code, following the existing code style.</p> </li> <li> <p>Add tests: If you are adding a new feature or fixing a bug, please consider adding tests to cover your changes. All existing tests must also pass. You can run the test suite with:</p> </li> </ol> <pre><code>pytest\n</code></pre> <ol> <li> <p>Commit the changes: RuneLog follows the Conventional Commits specification. This helps keep the project history clean and readable.</p> </li> <li> <p><code>feat</code>: for a new feature.</p> </li> <li><code>fix</code>: for a bug fix.</li> <li><code>docs</code>: for documentation changes.</li> <li><code>refactor</code>: for code changes that neither fix a bug nor add a feature.</li> <li> <p><code>test</code>: for adding or improving tests.</p> </li> <li> <p>Submit a Pull Request: Push your branch to your fork and open a pull request against the develop branch of the main repository.</p> </li> </ol>"},{"location":"CONTRIBUTING/#pull-request-checklist","title":"Pull Request Checklist","text":"<p>Before you submit your pull request, please make sure you have done the following:</p> <ul> <li> <p>[ ] My code follows the project's style guidelines.</p> </li> <li> <p>[ ] I have added tests that prove my fix is effective or that my feature works.</p> </li> <li> <p>[ ] I have updated the documentation where necessary.</p> </li> <li> <p>[ ] My pull request is targeted at the develop branch.</p> </li> </ul>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.</p> <p>Thank you for contributing!</p>"},{"location":"LICENSE/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2025 Alex Gonz\u00e1lez</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"cli/","title":"RuneLog Command-Line Interface (CLI)","text":"<p>The RuneLog CLI provides a powerful, terminal-based interface for interacting with your experiments, runs, and model registry. It's designed to be a fast and efficient alternative to the web UI for common tasks.</p>"},{"location":"cli/#installation","title":"Installation","text":"<p>The CLI is automatically installed when you install the <code>runelog</code> package:</p> <pre><code>pip install runelog\n</code></pre>"},{"location":"cli/#general-usage","title":"General Usage","text":"<p>All commands follow a standard structure. You can get help for any command or sub-command by adding the <code>--help</code> flag.</p> <pre><code>runelog [SUBCOMMAND] [COMMAND] [ARGUMENTS] [OPTIONS]\nrunelog experiments list --help\n</code></pre>"},{"location":"cli/#experiment-commands-runelog-experiments","title":"Experiment Commands (<code>runelog experiments</code>)","text":"<p>Manage and inspect your experiments.</p>"},{"location":"cli/#runelog-experiments-list","title":"<code>runelog experiments list</code>","text":"<p>Lists all available experiments in your project.</p> <pre><code>runelog experiments list\n</code></pre>"},{"location":"cli/#runelog-experiments-get","title":"<code>runelog experiments get</code>","text":"<p>Get details for a specific experiment.</p> <p>\ud83d\udea7 Note: This command is not yet fully implemented.</p> <pre><code>runelog experiments get &lt;EXPERIMENT_NAME_OR_ID&gt;\n</code></pre>"},{"location":"cli/#runelog-experiments-delete","title":"<code>runelog experiments delete</code>","text":"<p>Deletes an experiment and all of its associated runs. This action is irreversible.</p> <pre><code>runelog experiments delete &lt;EXPERIMENT_NAME_OR_ID&gt;\n</code></pre>"},{"location":"cli/#runelog-experiments-export","title":"<code>runelog experiments export</code>","text":"<p>Exports all run data (parameters and metrics) from a specific experiment to a CSV file.</p> <pre><code>runelog experiments export &lt;EXPERIMENT_NAME_OR_ID&gt; [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-o, --output TEXT</code>: Path to save the CSV file. Defaults to <code>&lt;experiment_name&gt;_export.csv</code>.</li> </ul> <p>Example:</p> <pre><code>runelog experiments export 0 -o my_experiment_results.csv\n</code></pre>"},{"location":"cli/#run-commands-runelog-runs","title":"Run Commands (<code>runelog runs</code>)","text":"<p>Manage and inspect individual runs.</p>"},{"location":"cli/#runelog-runs-list","title":"<code>runelog runs list</code>","text":"<p>Lists all runs for a given experiment.</p> <pre><code>runelog runs list &lt;EXPERIMENT_NAME_OR_ID&gt;\n</code></pre>"},{"location":"cli/#runelog-runs-get","title":"<code>runelog runs get</code>","text":"<p>Displays the detailed parameters, metrics, and artifacts for a specific run.</p> <pre><code>runelog runs get &lt;RUN_ID&gt;\n</code></pre>"},{"location":"cli/#runelog-runs-delete","title":"<code>runelog runs delete</code>","text":"<p>Deletes a specific run as well its parameters, metrics, and artifacts.</p> <pre><code>runelog runs delete &lt;RUN_ID&gt;\n</code></pre>"},{"location":"cli/#runelog-runs-download-artifact","title":"<code>runelog runs download-artifact</code>","text":"<p>Downloads an artifact file from a specific run to your local machine.</p> <pre><code>runelog runs download-artifact &lt;RUN_ID&gt; &lt;ARTIFACT_NAME&gt; [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-o, --output-path TEXT</code>: Directory to save the artifact. Defaults to the current directory.</li> </ul> <p>Example:</p> <pre><code>runelog runs download-artifact 8b2604f4 model.pkl -o ./downloaded_models/\n</code></pre>"},{"location":"cli/#runelog-runs-compare","title":"<code>runelog runs compare</code>","text":"<p>Displays a side-by-side comparison of the parameters and metrics for two or more runs.</p> <pre><code>runelog runs compare &lt;RUN_ID_1&gt; &lt;RUN_ID_2&gt; ...\n</code></pre>"},{"location":"cli/#registry-commands-runelog-registry","title":"Registry Commands (<code>runelog registry</code>)","text":"<p>Manage the model registry.</p>"},{"location":"cli/#runelog-registry-list","title":"<code>runelog registry list</code>","text":"<p>Lists all models in the registry and shows their latest version information.</p> <pre><code>runelog registry list\n</code></pre>"},{"location":"cli/#runelog-registry-get-versions","title":"<code>runelog registry get-versions</code>","text":"<p>Lists all available versions for a specific registered model.</p> <pre><code>runelog registry get-versions &lt;MODEL_NAME&gt;\n</code></pre>"},{"location":"cli/#runelog-registry-tag","title":"<code>runelog registry tag</code>","text":"<p>Adds or removes tags for a specific model version.</p> <pre><code>runelog registry tag &lt;MODEL_NAME&gt; &lt;VERSION&gt; [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-a, --add TEXT</code>: Tag to add/update in <code>key=value</code> format.</li> <li><code>-r, --remove TEXT</code>: Tag key to remove.</li> </ul> <p>Example:</p> <pre><code>runelog registry tag my-model 2 --add status=production --remove status=staging\n</code></pre>"},{"location":"cli/#interface-commands","title":"Interface Commands","text":""},{"location":"cli/#runelog-ui","title":"<code>runelog ui</code>","text":"<p>Launches the Runelog Streamlit web UI in your browser.</p> <p>Usage:</p> <pre><code>runelog ui\n</code></pre>"},{"location":"cli/#example-commands","title":"Example Commands","text":""},{"location":"cli/#runelog-examples","title":"<code>runelog examples</code>","text":"<p>Run the example scripts included with the library.</p> <p>Usage:</p> <pre><code>runelog examples [COMMAND]\n</code></pre> <p>Commands:</p> <ul> <li><code>minimal</code>: Runs the <code>minimal_tracking.py</code> example.</li> <li><code>train</code>: Runs the <code>train_model.py</code> example.</li> </ul>"},{"location":"dvc/","title":"DVC Integration Guide","text":"<p>RuneLog provides a lightweight integration with DVC (Data Version Control) to create a robust, reproducible link between your experiment runs and the exact version of the data you used.</p>"},{"location":"dvc/#example-workflow","title":"Example Workflow","text":""},{"location":"dvc/#1-version-your-data-with-dvc","title":"1. Version Your Data with DVC","text":"<p>Before running your experiment, use DVC to track your dataset. This command saves a \"fingerprint\" of your data in a small <code>.dvc</code> file, which you can commit to Git.</p> <pre><code>dvc add data/iris.csv\n\ngit add data/iris.csv.dvc\ngit commit -m \"data: track v1 of iris dataset\"\n</code></pre>"},{"location":"dvc/#2-log-the-dvc-input-in-your-script","title":"2. Log the DVC Input in Your Script","text":"<p>In your training script, use the <code>tracker.log_dvc_input()</code> method. It will find the <code>.dvc</code> file, read the unique data hash, and log it with your run.</p> <pre><code>from runelog import get_tracker\n\ntracker = get_tracker()\n\nwith tracker.start_run(experiment_name=\"model-with-dvc\"):\n    # This creates a permanent link to the data version\n    tracker.log_dvc_input(\"data/iris.csv\", name=\"training_set\")\n\n    # ... rest of your training and logging code\n</code></pre>"},{"location":"dvc/#3-view-the-results","title":"3. View the Results","text":"<p>Your run is now permanently linked to the specific version of your dataset. In the RuneLog UI, you can inspect the run to see the exact MD5 hash of the data that was used, ensuring full traceability.</p>"},{"location":"feature_store/","title":"The Lightweight Feature Store Pattern","text":"<p>This guide explains how to use <code>runelog</code> to create a simple, file-based \"feature store\" implementation. This pattern allows you to version your feature sets and create a clear, traceable lineage between your models and the exact features they were trained on, using only the core library features. While not as powerful as enterprise-level alternatives, it's a highly effective and storage-efficient pattern.</p>"},{"location":"feature_store/#workflow","title":"Workflow","text":"<p>The process involves two decoupled scripts:</p> <ul> <li> <p>A feature engineering script that generates a feature set, saves it to a known location, and logs a unique fingerprint (a SHA256 hash) of the data to a run.</p> </li> <li> <p>A model training script that discovers the latest feature set via a tag, verifies the integrity of the local data file against the logged fingerprint, and then trains a model.</p> </li> </ul> <p>This approach avoids duplicating large datasets, as only the metadata and hash are stored with the run, making it truly \"lightweight.\"</p>"},{"location":"feature_store/#the-fingerprint-method-recommended","title":"The Fingerprint Method (Recommended)","text":""},{"location":"feature_store/#feature-engineering-script","title":"Feature Engineering Script","text":"<p>This script processes data and uses log_dataset to record the feature set's metadata and hash. It then tags the run as latest for easy discovery.</p> <p><code>examples/feature_store/make_features.py</code></p> <pre><code>import os\nfrom sklearn.datasets import load_iris\nfrom runelog import get_tracker\n\n\ndef main():\n    tracker = get_tracker()\n\n    with tracker.start_run(experiment_name=\"feature-sets\") as run_id:\n        print(f\"Creating a new feature set in run: {run_id}\")\n\n        # Load and process data\n        iris = load_iris(as_frame=True)\n        df = iris.frame\n        df[\"sepal_area\"] = df[\"sepal length (cm)\"] * df[\"sepal width (cm)\"]\n\n        # Create a dedicated feature store folder\n        output_dir = os.path.join(\"fstore\", run_id)\n        os.makedirs(output_dir, exist_ok=True)\n        feature_path = os.path.join(output_dir, \"iris_features.parquet\")\n\n        # Save the feature set to the new, specific path\n        df.to_parquet(feature_path)\n\n        # Log the artifact from that path\n        tracker.log_artifact(feature_path)\n\n        print(f\"Feature set saved to '{feature_path}' and logged.\")\n\n        # Optional: Tag this run as the latest\n        tracker.set_run_tags({\"latest_feature_set\": True})\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Run this script with <code>python examples/feature_store/make_features.py</code> or use the CLI: <code>runelog examples features</code>. This will create a new run with a unique ID that represents a versioned feature set.</p>"},{"location":"feature_store/#create-the-model-training-script","title":"Create the Model Training Script","text":"<p>This script discovers the latest feature run, reads its logged dataset metadata, and verifies the local data file against the stored hash before training.</p> <p><code>examples/feature_store/train_with_fs.py</code></p> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nfrom runelog import get_tracker, exceptions\n\n# The experiment where feature generation runs are stored\nFEATURE_EXPERIMENT = \"feature-sets\"\n\n# The consistent filename of the artifact we want to use\nARTIFACT_FILENAME = \"iris_features.parquet\"\n\n\ndef find_latest_feature_run(tracker) -&gt; str:\n    \"\"\"Finds the most recent run in the feature experiment.\"\"\"\n    try:\n        all_runs_df = tracker.load_results(FEATURE_EXPERIMENT)\n        if all_runs_df.empty:\n            print(f\"Error: No runs found in experiment '{FEATURE_EXPERIMENT}'.\")\n            return None\n\n        all_runs_df[\"start_time\"] = pd.to_datetime(all_runs_df[\"start_time\"])\n        sorted_runs = all_runs_df.sort_values(by=\"start_time\", ascending=False)\n\n        latest_run_id = sorted_runs.index[0]\n        print(f\"Found latest feature set from run: {latest_run_id}\")\n        return latest_run_id\n\n    except exceptions.ExperimentNotFound:\n        print(f\"Error: Experiment '{FEATURE_EXPERIMENT}' not found.\")\n        return None\n\n\ndef main():\n    \"\"\"\n    Finds the latest feature set, trains a model, and logs the results.\n    \"\"\"\n    tracker = get_tracker()\n\n    feature_run_id = find_latest_feature_run(tracker)\n    if not feature_run_id:\n        print(\"Could not find a feature set to train on. Exiting.\")\n        return\n\n    # Download the artifact using its consistent filename\n    print(f\"Downloading artifact '{ARTIFACT_FILENAME}' from run '{feature_run_id}'...\")\n    feature_path = tracker.download_artifact(feature_run_id, ARTIFACT_FILENAME)\n    df = pd.read_parquet(feature_path)\n\n    # Start a new run for the model training\n    with tracker.start_run(experiment_name=\"production-models\"):\n\n        # Track lineage using the artifact's filename\n        tracker.log_input_run(\n            name=\"feature_set\", run_id=feature_run_id, artifact_name=ARTIFACT_FILENAME\n        )\n\n        # Train a model on the versioned data\n        X = df.drop(columns=[\"target\"])\n        y = df[\"target\"]\n        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\n        params = {\"C\": 50, \"max_iter\": 10_000}\n\n        model = LogisticRegression(**params).fit(X_train, y_train)\n        accuracy = accuracy_score(y_test, model.predict(X_test))\n\n        tracker.log_metric(\"accuracy\", accuracy)\n        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Run this script with <code>python examples/feature_store/train_with_fs.py</code> or use the CLI: <code>runelog examples train-fs</code>.</p> <p>You now have a model training run that is permanently and traceably linked to the exact version of the features it was trained on.</p>"},{"location":"feature_store/#alternative-workflows","title":"Alternative Workflows","text":""},{"location":"feature_store/#using-full-artifacts","title":"Using Full Artifacts","text":"<p>For smaller datasets or when you need fully self-contained runs, you can log the entire dataset as an artifact.</p> <p>In <code>make_features.py</code>, replace <code>tracker.log_dataset(...)</code> with <code>tracker.log_artifact(...)</code>:</p> <pre><code># make_features.py\n# ...\ndf.to_parquet(\"iris_features.parquet\")\n# Log the entire file as an artifact\ntracker.log_artifact(\"iris_features.parquet\")\n</code></pre> <p>The training script would then download the artifact directly instead of verifying a local file.</p> <pre><code># In train_with_fs.py\n# ...\n# Download the artifact instead of verifying a local file\nfeature_path = tracker.download_artifact(feature_run_id, \"iris_features.parquet\")\ndf = pd.read_parquet(feature_path)\n\nwith tracker.start_run(experiment_name=MODEL_EXPERIMENT):\n    # Use log_input_run for a direct artifact-to-run link\n    tracker.log_input_run(\n        name=\"feature_set\",\n        run_id=feature_run_id,\n        artifact_name=\"iris_features.parquet\"\n    )\n    # ... rest of training code\n</code></pre>"},{"location":"feature_store/#integrating-with-dvc","title":"Integrating with DVC","text":"<p>If you already use DVC to version your data, you can use <code>log_dvc_input</code> to create the link. This method finds the <code>.dvc</code> file, extracts the version hash (MD5), and logs it.</p> <p>Simply replace log_dataset in your feature script:</p> <pre><code># In make_features.py, after saving the data and running `dvc add data/iris_features.parquet`\n\n# tracker.log_dataset(FEATURE_PATH, name=\"iris_features\") # Old method\ntracker.log_dvc_input(FEATURE_PATH, name=\"iris_features\") # New method\nprint(f\"DVC version info for '{FEATURE_PATH}' was logged.\")\n</code></pre>"},{"location":"interface/","title":"Runelog UI User Guide","text":"<p>Welcome to the user guide for the RuneLog web interface, which will walk you through the main features of the application.</p>"},{"location":"interface/#launching-the-app","title":"Launching the App","text":"<p>To start the user interface, navigate to your project's root directory in your terminal and run:</p> <pre><code>streamlit run app/main.py\n</code></pre> <p>You can also use the CLI:</p> <pre><code>streamlit ui\n</code></pre> <p>This will open the application in a new browser tab.</p>"},{"location":"interface/#the-experiment-explorer","title":"The Experiment Explorer \ud83d\udd2c","text":"<p>This is the main view for analyzing your experiment runs. After selecting an experiment from the top dropdown, you can either inspect a single run or compare multiple runs.</p>"},{"location":"interface/#selecting-an-experiment","title":"Selecting an Experiment","text":"<p>Use the dropdown menu at the top of the page to choose which experiment you want to inspect. The table will automatically update to show all the runs for that experiment.</p>"},{"location":"interface/#inspecting-a-single-run","title":"Inspecting a Single Run","text":"<p>The main table gives you a high-level overview of all your runs. To see the details for a specific run:</p> <ol> <li>Find the <code>run_id</code> of the run you are interested in from the table.</li> <li>Use the searchable dropdown labeled \"Select a run to view its details\" to find and select that <code>run_id</code>.</li> <li>A detailed view will appear below the table, showing the specific Parameters, Metrics, and Artifacts for that run.</li> </ol>"},{"location":"interface/#comparing-multiple-runs","title":"Comparing Multiple Runs","text":"<p>The explorer also allows you to visually compare the performance of multiple runs.</p> <ol> <li>Use the \"Select runs to view details or compare\" dropdown and select two or more runs from the list.</li> <li>A \"Compare Selected Runs\" section will appear below the table.</li> <li>Choose a metric from the new dropdown to plot the comparison. A bar chart will instantly show you the results, making it easy to see which run performed best.</li> </ol>"},{"location":"interface/#the-model-registry","title":"The Model Registry \ud83d\udcda","text":"<p>Navigate to the Model Registry using the sidebar link. This page allows you to view all your \"blessed\" or production-ready models that have been versioned for easy access.</p>"},{"location":"interface/#viewing-model-versions","title":"Viewing Model Versions","text":"<ol> <li>On the left, select a registered model from the list.</li> <li>The right side of the screen will update to show all available versions for that model, with the latest version at the top.</li> <li>Click on any version to expand it and see its details.</li> </ol>"},{"location":"interface/#understanding-version-details","title":"Understanding Version Details","text":"<p>Inside each version's expander, you will find:</p> <ul> <li>Tags: Any tags assigned to this version (e.g., <code>status: production</code>).</li> <li>Source Run ID: A reference to the original experiment run that produced this model.</li> <li>Metrics &amp; Parameters: The exact metrics and parameters from the source run, giving you full traceability.</li> <li>Source Artifacts: A list of all artifacts that were created during the source run.</li> </ul>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#you-first-runelog-experiment","title":"You First RuneLog Experiment","text":"<p>Welcome to Runelog! This guide will walk you through the entire process of tracking a simple machine learning model.</p>"},{"location":"quickstart/#step-1-installation","title":"Step 1: Installation","text":"<p>If you haven't already, install the runelog library from PyPI:</p> <pre><code>pip install runelog\n</code></pre>"},{"location":"quickstart/#step-2-create-a-training-script","title":"Step 2: Create a Training Script","text":"<p>Create a new Python file (e.g., quickstart.py) and paste the following code into it. This script trains a simple classification model and uses runelog to track its parameters and performance.</p> <pre><code>from runelog import get_tracker\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\n\n# 1. Initialize the tracker\n# This is the main entry point to the RuneLog library.\ntracker = get_tracker()\n\n# 2. Start a new run within an experiment\n# If \"quickstart-example\" doesn't exist, it will be created automatically.\nwith tracker.start_run(experiment_name=\"quickstart-example\"):\n\n    # Define and log the model's hyperparameters\n    params = {\"solver\": \"liblinear\", \"C\": 0.5}\n    tracker.log_parameter(\"solver\", params[\"solver\"])\n    tracker.log_parameter(\"C\", params[\"C\"])\n    print(\"Logged parameters:\", params)\n\n    # Your model training logic\n    X, y = make_classification(n_samples=100, random_state=0)\n    model = LogisticRegression(**params).fit(X, y)\n\n    # Log the model's performance metric\n    accuracy = accuracy_score(y, model.predict(X))\n    tracker.log_metric(\"accuracy\", accuracy)\n    print(f\"Logged accuracy: {accuracy:.4f}\")\n\n    # Log the trained model file as an artifact\n    tracker.log_model(model, \"logreg.pkl\")\n    print(\"Logged model: logreg.pkl\")\n\nprint(\"\\nRun finished!\")\n</code></pre>"},{"location":"quickstart/#step-3-run-the-script","title":"Step 3: Run the Script","text":"<p>Execute the script from your terminal:</p> <pre><code>python quickstart.py\n</code></pre> <p>You will see the logged parameters and metrics printed to your console. In the background, RuneLog has saved all of this information into a new <code>.mlruns</code> directory.</p>"},{"location":"quickstart/#step-4-review-results-in-the-ui","title":"Step 4: Review Results in the UI","text":"<p>Launch the Streamlit UI with the following command:</p> <pre><code># Make sure you are in the same root directory where your .mlruns folder was created\nstreamlit run app/main.py\n</code></pre> <p>Your browser will now open the Experiment Explorer. Select the \"Quickstart Example\" experiment, and you will see the run you just completed, along with its parameters and metrics, in a clean, interactive table.</p>"},{"location":"reference/","title":"\ud83e\uddfe API Reference","text":""},{"location":"reference/#main-tracker","title":"Main Tracker","text":""},{"location":"reference/#runelog.runelog.RuneLog","title":"<code>RuneLog(path='.')</code>","text":"<p>A lightweight tracker for ML experiments.</p> <p>This class handles the creation of experiments, management of runs, and logging of parameters, metrics, and artifacts to the local filesystem. It also provides a model registry for versioning and managing models.</p> <p>Initializes the tracker and creates required directories.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The root directory for storing all tracking data. Defaults to the current directory.</p> <code>'.'</code>"},{"location":"reference/#runelog.runelog.RuneLog.add_model_tags","title":"<code>add_model_tags(model_name, version, tags)</code>","text":"<p>Retrieves the tags for a specific registered model version.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the registered model.</p> required <code>version</code> <code>str</code> <p>The version from which to retrieve tags.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary of the model version's tags.</p> <p>Raises:</p> Type Description <code>ModelVersionNotFound</code> <p>If the model or version is not found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.delete_experiment","title":"<code>delete_experiment(experiment_name_or_id)</code>","text":"<p>Deletes an experiment and all of its associated runs and artifacts. This is a destructive operation and cannot be undone.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name_or_id</code> <code>str</code> <p>The name or ID of the experiment to delete.</p> required <p>Raises:</p> Type Description <code>ExperimentNotFound</code> <p>If no experiment with the given name or ID is found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.delete_run","title":"<code>delete_run(run_id)</code>","text":"<p>Deletes a run and all of its associated artifacts.</p> <p>This is a destructive operation and cannot be undone.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>The ID of the run to delete.</p> required <p>Raises:</p> Type Description <code>RunNotFound</code> <p>If no run with the given ID is found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.download_artifact","title":"<code>download_artifact(run_id, artifact_name, destination_path='.')</code>","text":"<p>Downloads an artifact from a specific run to a local path.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>The ID of the run containing the artifact.</p> required <code>artifact_name</code> <code>str</code> <p>The filename of the artifact to download.</p> required <code>destination_path</code> <code>str</code> <p>The local directory to save the artifact in. Defaults to the current directory.</p> <code>'.'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The absolute path to the downloaded artifact.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_artifact_abspath","title":"<code>get_artifact_abspath(run_id, artifact_name)</code>","text":"<p>Gets the absolute path of a specific artifact from a given run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>The ID of the run containing the artifact.</p> required <code>artifact_name</code> <code>str</code> <p>The filename of the artifact.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The absolute, local path to the artifact file.</p> <p>Raises:</p> Type Description <code>RunNotFound</code> <p>If the run ID does not exist.</p> <code>ArtifactNotFound</code> <p>If the artifact name does not exist in the run.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_experiment","title":"<code>get_experiment(experiment_id)</code>","text":"<p>Gets the metadata for a single experiment by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>The ID of the experiment to retrieve.</p> required <p>Returns:</p> Type Description <code>Optional[Dict]</code> <p>Optional[Dict]: A dictionary containing the experiment's metadata, or None if not found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_experiment_runs","title":"<code>get_experiment_runs(experiment_id, sort_by='timestamp', ascending=True)</code>","text":"<p>Return a list of individual runs for the given experiment.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_id</code> <code>str</code> <p>The ID of the experiment to query.</p> required <code>sort_by</code> <code>Optional[str]</code> <p>Field to sort runs by (e.g., \"timestamp\"). Defaults to \"timestamp\". Set to None to disable sorting.</p> <code>'timestamp'</code> <code>ascending</code> <code>bool</code> <p>Sort order. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: A list of run dictionaries.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_experiment_summaries","title":"<code>get_experiment_summaries(sort_by=None, ascending=True)</code>","text":"<p>Obtain summaries for all experiments, including run statistics: number of runs, the timestamp of the most recent run, and the creation time of the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>sort_by</code> <code>Optional[str]</code> <p>Field to sort summaries by (e.g., \"name\", \"num_runs\", \"last_run\"). Defaults to None (no sorting).</p> <code>None</code> <code>ascending</code> <code>bool</code> <p>Sort order. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: A list of dictionaries, each representing a summarized view</p> <code>List[Dict]</code> <p>of an experiment. Each dictionary contains: - experiment_id (str): Unique identifier of the experiment. - name (str): Human-readable name of the experiment. - created_at (str | None): ISO 8601 timestamp of the experiment's creation, or None if not available. - num_runs (int): Total number of runs recorded for the experiment. - last_run (str | None): ISO 8601 timestamp of the most recent run, or None if no runs exist.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_model_tags","title":"<code>get_model_tags(model_name, version)</code>","text":"<p>Retrieves the tags for a specific registered model version.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the registered model.</p> required <code>version</code> <code>str</code> <p>The version from which to retrieve tags.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>dict</code> <p>A dictionary of the model version's tags.</p> <p>Raises:</p> Type Description <code>ModelVersionNotFound</code> <p>If the model or version is not found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_model_versions","title":"<code>get_model_versions(model_name, sort_by='version', ascending=False)</code>","text":"<p>Gets all versions and their metadata for a registered model.</p> <p>The versions are returned sorted from newest to oldest.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model to retrieve versions for.</p> required <code>sort_by</code> <code>Optional[str]</code> <p>Field to sort by (e.g., \"version\", \"registration_timestamp\"). Sorted by 'version' by default.</p> <code>'version'</code> <code>ascending</code> <code>bool</code> <p>Sort order. Defaults to True (newest first).</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: A list of metadata dictionaries, where each dictionary represents a single version of the model. Returns an empty list if the model is not found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_or_create_experiment","title":"<code>get_or_create_experiment(name)</code>","text":"<p>Gets an existing experiment by name or creates a new one.</p> <p>If an experiment with the given name already exists, its ID is returned. Otherwise, a new experiment is created.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the experiment.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The unique ID of the new or existing experiment.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_run","title":"<code>get_run(run_id)</code>","text":"<p>Loads the parameters and metrics for a specific run.</p> <p>This method provides a summarized view of a run's data, primarily for use in creating tabular summaries like in <code>load_results</code>. It assumes that <code>run_id</code> is unique across all experiments.</p> Note <p>For a more detailed dictionary that includes artifacts, see the <code>get_run_details()</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>The unique ID of the run to retrieve.</p> required <p>Returns:</p> Type Description <code>Optional[Dict]</code> <p>Optional[Dict]: A dictionary containing the <code>run_id</code> and all associated parameters and metrics, or None if the run is not found. Parameter keys are prefixed with 'param_'.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_run_details","title":"<code>get_run_details(run_id)</code>","text":"<p>Loads all details for a specific run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>The unique ID of the run to retrieve.</p> required <p>Returns:</p> Type Description <code>Optional[Dict]</code> <p>Optional[Dict]: A dictionary containing the run's 'params', 'metrics', and 'artifacts', or None if the run is not found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.get_run_tags","title":"<code>get_run_tags()</code>","text":"<p>Retrieves the tags for the active run.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary of the run's tags. Returns an empty dict if no tags are set.</p>"},{"location":"reference/#runelog.runelog.RuneLog.list_experiments","title":"<code>list_experiments()</code>","text":"<p>Lists all available experiments.</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: A list of dictionaries, where each dictionary contains the metadata of an experiment (e.g., name and ID).</p>"},{"location":"reference/#runelog.runelog.RuneLog.list_registered_models","title":"<code>list_registered_models(ascending=True)</code>","text":"<p>Lists the names of all models in the registry.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of names of all registered models.</p>"},{"location":"reference/#runelog.runelog.RuneLog.load_registered_model","title":"<code>load_registered_model(model_name, version='latest')</code>","text":"<p>Loads a model from the model registry.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the registered model.</p> required <code>version</code> <code>str</code> <p>The version to load. Can be a specific version number or \"latest\". Defaults to \"latest\".</p> <code>'latest'</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The loaded model object.</p> <p>Raises:</p> Type Description <code>ModelNotFound</code> <p>If no model with the given name is found.</p> <code>NoVersionsFound</code> <p>If the model exists but has no versions.</p> <code>ModelVersionNotFound</code> <p>If the specified version is not found for the model.</p>"},{"location":"reference/#runelog.runelog.RuneLog.load_results","title":"<code>load_results(experiment_name_or_id, sort_by=None, ascending=True)</code>","text":"<p>Loads all run data from an experiment into a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name_or_id</code> <code>str</code> <p>The ID of the experiment to load.</p> required <code>sort_by</code> <code>Optional[str]</code> <p>Column to sort the DataFrame by. Defaults to None (sort by run_id index).</p> <code>None</code> <code>ascending</code> <code>bool</code> <p>Sort order. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing the parameters and metrics for each run in the experiment, indexed by <code>run_id</code>. Returns an empty DataFrame if the experiment has no runs.</p> <p>Raises:</p> Type Description <code>ExperimentNotFound</code> <p>If no experiment with the given ID is found.</p>"},{"location":"reference/#runelog.runelog.RuneLog.log_artifact","title":"<code>log_artifact(local_path)</code>","text":"<p>Logs a local file as an artifact of the active run.</p> <p>Parameters:</p> Name Type Description Default <code>local_path</code> <code>str</code> <p>The local path to the file to be logged as an artifact.</p> required <p>Raises:</p> Type Description <code>NoActiveRun</code> <p>If called outside of an active run context.</p> <code>ArtifactNotFound</code> <p>If the file at <code>local_path</code> does not exist.</p>"},{"location":"reference/#runelog.runelog.RuneLog.log_dataset","title":"<code>log_dataset(data_path, name)</code>","text":"<p>Logs the hash and metadata of a dataset file.</p> <p>This creates a verifiable \"fingerprint\" of the data used in a run, ensuring data lineage and reproducibility.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>str</code> <p>The local path to the dataset file.</p> required <code>name</code> <code>str</code> <p>A descriptive name for the dataset.</p> required"},{"location":"reference/#runelog.runelog.RuneLog.log_dvc_input","title":"<code>log_dvc_input(data_path, name)</code>","text":"<p>Logs the version hash of a DVC-tracked file.</p> <p>This method finds the corresponding .dvc file for the given data path, parses it to find the MD5 hash of the data version, and logs this information to a dedicated <code>dvc_inputs.json</code> file in the run directory. This creates a verifiable link between the run and the exact version of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>str</code> <p>The path to the data file tracked by DVC (e.g., \"data/my_data.csv\").</p> required <code>name</code> <code>str</code> <p>A descriptive name for this data input.</p> required"},{"location":"reference/#runelog.runelog.RuneLog.log_input_run","title":"<code>log_input_run(name, run_id, artifact_name=None)</code>","text":"<p>Logs a dependency on another run, creating a lineage link.</p> <p>This is used to create verifiable links to upstream runs and their artifacts, for example, to specify that a model training run used the output from a specific feature generation run. The information is saved to a <code>lineage.json</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>A logical name for the input.</p> required <code>run_id</code> <code>str</code> <p>The unique ID of the run being used as an input.</p> required <code>artifact_name</code> <code>Optional[str]</code> <p>The specific artifact from</p> <code>None</code>"},{"location":"reference/#runelog.runelog.RuneLog.log_metric","title":"<code>log_metric(key, value)</code>","text":"<p>Logs a single metric for the active run.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the metric.</p> required <code>value</code> <code>float</code> <p>The value of the metric.</p> required <p>Raises:</p> Type Description <code>NoActiveRun</code> <p>If called outside of an active run context.</p>"},{"location":"reference/#runelog.runelog.RuneLog.log_model","title":"<code>log_model(model, name, compress=3)</code>","text":"<p>Logs a trained model as an artifact of the active run.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Any</code> <p>The trained model object to be saved (e.g., a scikit-learn model).</p> required <code>name</code> <code>str</code> <p>The filename for the saved model (e.g., \"model.pkl\").</p> required <code>compress</code> <code>int</code> <p>The level of compression for joblib from 0 to 9. Defaults to 3.</p> <code>3</code> <p>Raises:</p> Type Description <code>NoActiveRun</code> <p>If called outside of an active run context.</p>"},{"location":"reference/#runelog.runelog.RuneLog.log_param","title":"<code>log_param(key, value)</code>","text":"<p>Logs a single parameter for the active run.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the parameter.</p> required <code>value</code> <code>Any</code> <p>The value of the parameter. Must be JSON-serializable.</p> required <p>Raises:</p> Type Description <code>NoActiveRun</code> <p>If called outside of an active run context.</p>"},{"location":"reference/#runelog.runelog.RuneLog.register_model","title":"<code>register_model(run_id, artifact_name, model_name, tags=None)</code>","text":"<p>Registers a model from a run's artifacts to the model registry.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>The ID of the run where the model artifact is stored.</p> required <code>artifact_name</code> <code>str</code> <p>The filename of the model artifact (e.g., \"model.pkl\").</p> required <code>model_name</code> <code>str</code> <p>The name to register the model under. This can be a new or existing model name.</p> required <code>tags</code> <code>Optional[Dict]</code> <p>A dictionary of tags to add to the new model version. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The new version number of the registered model as a string.</p> <p>Raises:</p> Type Description <code>RunNotFound</code> <p>If no run with the given ID is found.</p> <code>ArtifactNotFound</code> <p>If the specified artifact is not found in the run.</p>"},{"location":"reference/#runelog.runelog.RuneLog.set_run_tags","title":"<code>set_run_tags(tags)</code>","text":"<p>Sets the entire tag dictionary for the active run.</p> <p>This will overwrite any existing tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Dict</code> <p>The dictionary of tags to set for the run.</p> required"},{"location":"reference/#runelog.runelog.RuneLog.start_run","title":"<code>start_run(experiment_name=None, experiment_id='0', log_git_meta=True, log_env=False, log_code=True)</code>","text":"<p>Starts a new run within an experiment as a context manager.</p> <p>This is the primary method for creating a new run. It handles run creation, status updates, and can optionally log metadata about the execution environment for reproducibility.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>The name of the experiment. If it doesn't exist, it will be created. This takes precedence over <code>experiment_id</code>. Defaults to None.</p> <code>None</code> <code>experiment_id</code> <code>str</code> <p>The ID of the experiment. If neither name nor ID is provided, it defaults to \"0\" (the \"Default\" experiment). Defaults to None.</p> <code>'0'</code> <code>log_git_meta</code> <code>bool</code> <p>If True, logs Git metadata (commit hash, branch, dirty status) to a <code>source_control.json</code> file. Defaults to True.</p> <code>True</code> <code>log_env</code> <code>bool</code> <p>If True, logs the Python environment (version, platform, packages) to <code>environment.json</code> and a <code>requirements.txt</code> artifact. Defaults to False.</p> <code>False</code> <code>log_code</code> <code>bool</code> <p>If True, logs the source code file as an artifact. Defaults to True.</p> <code>True</code> <p>Yields:</p> Name Type Description <code>str</code> <code>str</code> <p>The unique ID of the newly created run.</p> Example <p>tracker = get_tracker() with tracker.start_run( ...     experiment_name=\"example-experiment\", ...     log_env=True ... ) as run_id: ...     tracker.log_metric(\"accuracy\", 0.95)</p>"}]}